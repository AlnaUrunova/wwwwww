from nltk import sent_tokenize, pos_tag
from nltk.tokenize import TreebankWordTokenizer
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet as wn
from nltk.corpus import sentiwordnet as swn
from nltk.sentiment.util import mark_negation
from string import punctuation
from IPython.display import display
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

import nltk
import shutil


# Скачиваем ВСЕ необходимые ресурсы
nltk.download('all', halt_on_error=False)


test_text = "This is a test. NLTK is working?"
try:
    print(sent_tokenize(test_text))
    print("NLTK работает корректно!")
except:
    print("Проблема с NLTK. Используем альтернативный метод")




pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', None)



#Sentiment Scoring Using SentiWordNet



def penn_to_wn(tag):
    """
        Convert between the PennTreebank tags to simple Wordnet tags
    """
    if tag.startswith('J'):
        return wn.ADJ
    elif tag.startswith('N'):
        return wn.NOUN
    elif tag.startswith('R'):
        return wn.ADV
    elif tag.startswith('V'):
        return wn.VERB
    return None


def get_sentiment_score(text):
    
    """
        This method returns the sentiment score of a given text using SentiWordNet sentiment scores.
        input: text
        output: numeric (double) score, >0 means positive sentiment and <0 means negative sentiment.
    """    
    total_score = 0
    #print(text)
    raw_sentences = sent_tokenize(text)
    #print(raw_sentences)
    
    for sentence in raw_sentences:

        sent_score = 0     
        sentence = str(sentence)
        #print(sentence)
        sentence = sentence.replace("<br />"," ").translate(str.maketrans('','',punctuation)).lower()
        tokens = TreebankWordTokenizer().tokenize(text)
        tags = pos_tag(tokens)
        for word, tag in tags:
            wn_tag = penn_to_wn(tag)
            if not wn_tag:
                continue
            lemma = WordNetLemmatizer().lemmatize(word, pos=wn_tag)
            if not lemma:
                continue
            synsets = wn.synsets(lemma, pos=wn_tag)
            if not synsets:
                continue
            synset = synsets[0]
            swn_synset = swn.senti_synset(synset.name())
            sent_score += swn_synset.pos_score() - swn_synset.neg_score()

        total_score = total_score + (sent_score / len(tokens))

    
    return (total_score / len(raw_sentences)) * 100


reviews = pd.read_csv("data/small_corpus.csv")


reviews.shape


reviews.head()


reviews.dropna(subset=['comment'], inplace=True)



reviews.shape


reviews['swn_score'] = reviews['comment'].apply(lambda text : get_sentiment_score(text))


reviews[['comment','swn_score']].sample(2)


reviews[['comment','swn_score']].sample(2)


fig , ax = plt.subplots(nrows=1, ncols=1, figsize=(20,10))
sns.histplot(x='swn_score', data=reviews.query("swn_score < 8 and swn_score > -8"), ax=ax)
plt.show()

reviews['swn_sentiment'] = reviews['swn_score'].apply(lambda x: "positive" if x>1 else ("negative" if x<0.5 else "neutral"))


reviews['swn_sentiment'].value_counts(dropna=False)


sns.countplot(x='rating', hue='swn_sentiment' ,data = reviews)

sns.boxenplot(x='swn_sentiment', y='rating', data = reviews)

fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (12,7))
sns.boxenplot(x='rating', y='swn_score', data = reviews, ax=ax)
plt.show()

reviews['true_sentiment'] = \
    reviews['rating'].apply(lambda x: "positive" if x>=4 else ("neutral" if x==3 else "negative"))


y_swn_pred, y_true = reviews['swn_sentiment'].tolist(), reviews['true_sentiment'].tolist()


len(y_swn_pred), len(y_true)


from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_true, y_swn_pred)


fig , ax = plt.subplots(nrows=1, ncols=1, figsize=(8,6))
sns.heatmap(cm, cmap='viridis_r', annot=True, fmt='d', square=True, ax=ax)
ax.set_xlabel('Predicted')
ax.set_ylabel('True')

#Performance Assessment

#Negative Sentiment Prediction Assessment
tp, tn, fp, fn = 1088, 70+242+142+1310, 265+647, 188+547

recall = tp / (tp+fn)
specifity = tn / (tn+fp)
precision = tp/(tp+fp)
f1 = (2*tp) / (2*tp + fp + fn)

print("recall: {}\nprecission: {}\nf1 score: {}".format(recall, precision, f1))


tp, tn, fp, fn = 1310, 1088+265+70+188, 242+647, 142+547

recall = tp / (tp+fn)
specifity = tn / (tn+fp)
precision = tp/(tp+fp)
f1 = (2*tp) / (2*tp + fp + fn)


print("recall: {}\nprecission: {}\nf1 score: {}".format(recall, precision, f1))


#Sentiment Scoring Model Using NLTK Opinion Lexicon


import nltk
from nltk.corpus import opinion_lexicon
from nltk.tokenize import word_tokenize, sent_tokenize

nltk.download("opinion_lexicon")

pos_words = list(opinion_lexicon.positive())
neg_words = list(opinion_lexicon.negative())


def get_sentiment_score_oplex(text):
    
    """
        This method returns the sentiment score of a given text using nltk opinion lexicon.
        input: text
        output: numeric (double) score, >0 means positive sentiment and <0 means negative sentiment.
    """    
    total_score = 0

    raw_sentences = sent_tokenize(text)
    
    for sentence in raw_sentences:

        sent_score = 0     
        sentence = str(sentence)
        sentence = sentence.replace("<br />"," ").translate(str.maketrans('','',punctuation)).lower()
        tokens = TreebankWordTokenizer().tokenize(text)
        for token in tokens:
            sent_score = sent_score + 1 if token in pos_words else (sent_score - 1 if token in neg_words else sent_score)
        total_score = total_score + (sent_score / len(tokens))

    
    return total_score

reviews['oplex_sentiment_score'] = reviews['comment'].apply(lambda x: get_sentiment_score_oplex(x))



fig , ax = plt.subplots(nrows=1, ncols=1, figsize=(20,10))
sns.histplot(x='oplex_sentiment_score',\
             data=reviews.query("oplex_sentiment_score < 1 and oplex_sentiment_score>-1"), ax=ax)
plt.show()


reviews['oplex_sentiment'] = \
    reviews['oplex_sentiment_score'].apply(lambda x: "positive" if x>0.1 else ("negative" if x<0 else "neutral"))


reviews['oplex_sentiment'].value_counts(dropna=False)

sns.countplot(x='rating', hue='oplex_sentiment' ,data = reviews)

sns.boxenplot(x='oplex_sentiment', y='rating', data = reviews)

fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (12,7))
sns.boxenplot(x='rating', y='oplex_sentiment_score', data = reviews, ax=ax)
plt.show()

y_oplex_pred = reviews['oplex_sentiment'].tolist()

oplex_cm = confusion_matrix(y_true, y_oplex_pred)



fig , ax = plt.subplots(nrows=1, ncols=1, figsize=(8,6))
sns.heatmap(oplex_cm, cmap='viridis_r', annot=True, fmt='d', square=True, ax=ax)
ax.set_xlabel('Predicted')
ax.set_ylabel('True')

oplex_cm = list(oplex_cm.ravel())

oplex_cm

#Negative Label Assessment

tp, tn, fp, fn = 804, 195+199+686+1181, 106+132, 701+495

recall = tp / (tp+fn)
specifity = tn / (tn+fp)
precision = tp/(tp+fp)
f1 = (2*tp) / (2*tp + fp + fn)

print("recall: {}\nprecission: {}\nf1 score: {}".format(recall, precision, f1))



#Positive Label Assessment

tp, tn, fp, fn = 1181, 804+701+106+195, 495+199, 132+686

recall = tp / (tp+fn)
specifity = tn / (tn+fp)
precision = tp/(tp+fp)
f1 = (2*tp) / (2*tp + fp + fn)

print("recall: {}\nprecission: {}\nf1 score: {}".format(recall, precision, f1))